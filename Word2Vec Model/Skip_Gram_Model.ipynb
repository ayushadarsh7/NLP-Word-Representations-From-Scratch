{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "corpus_files = ['/content/pre_processed_corpus/corpus_1.txt',\n",
        "                '/content/pre_processed_corpus/corpus_2.txt',\n",
        "                '/content/pre_processed_corpus/corpus_3.txt',\n",
        "                '/content/pre_processed_corpus/corpus_4.txt']\n",
        "\n",
        "corpus = ''\n",
        "for file in corpus_files:\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        corpus += f.read()\n",
        "\n",
        "corpus = corpus.replace('\\n', ' ').split()\n",
        "vocab = list(set(corpus))\n",
        "vocab_size = len(vocab)\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "def cross_entropy_loss(output, target):\n",
        "    output_probs = np.exp(output) / np.sum(np.exp(output))\n",
        "    return -np.log(output_probs[target])\n",
        "\n"
      ],
      "metadata": {
        "id": "9zJWXgC_XxR4"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram:\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.w_in = np.random.rand(vocab_size, embedding_dim)\n",
        "        self.w_out = np.random.rand(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_word):\n",
        "        input_idx = word2idx[input_word]\n",
        "        input_embedding = self.w_in[input_idx]\n",
        "        output = np.dot(input_embedding, self.w_out)\n",
        "        return output\n",
        "\n",
        "    def backward(self, input_word, context_word):\n",
        "        input_idx = word2idx[input_word]\n",
        "        context_idx = word2idx[context_word]\n",
        "        input_embedding = self.w_in[input_idx]\n",
        "        output_embedding = self.w_out[:, context_idx]\n",
        "        error = output_embedding - input_embedding\n",
        "        self.w_in[input_idx] -= 0.01 * error\n",
        "        self.w_out[:, context_idx] -= 0.01 * error\n",
        "\n",
        "    def train(self, corpus, window_size):\n",
        "        for sentence in corpus:\n",
        "            words = sentence.split()\n",
        "            for i, word in enumerate(words):\n",
        "                context_words = words[max(0, i-window_size):i] + words[i+1:min(len(words), i+window_size+1)]\n",
        "                for context_word in context_words:\n",
        "                    self.backward(word, context_word)\n",
        "\n",
        "    def generate_text(self, input_word, num_words):\n",
        "        input_idx = word2idx[input_word]\n",
        "        input_embedding = self.w_in[input_idx]\n",
        "        output = np.dot(input_embedding, self.w_out)\n",
        "        output_probs = np.exp(output) / np.sum(np.exp(output))\n",
        "        generated_words = []\n",
        "        for _ in range(num_words):\n",
        "            sampled_idx = np.random.choice(range(vocab_size), p=output_probs)\n",
        "            generated_words.append(idx2word[sampled_idx])\n",
        "        return ' '.join(generated_words)\n"
      ],
      "metadata": {
        "id": "eFJqUUqAa5VH"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SkipGram(vocab_size, 100)\n",
        "model.train(corpus, window_size=5)"
      ],
      "metadata": {
        "id": "A1ywRNnQX1xw"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(input_word, num_words):\n",
        "    generated_text = model.generate_text(input_word, num_words)\n",
        "    print(f'Generated text: {generated_text}')\n",
        "\n",
        "\n",
        "test_model('मजदूरों', 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXCvKpp0a886",
        "outputId": "a321f01f-18cc-447f-f058-d4cef6b6680c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: दिखाते सत्कार खदानों जगहजगह\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbpSRJObbEVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}